{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Model we will build: classification. Classification basically groups data points by telling us all classes each data point can have.\n",
    "\n",
    "Importing everything we need."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will use a flower dataset based on sepal length & width and petal length & width. We have to find which species each flower belongs to."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "COLUMN_NAMES = ['SepalLength','SepalWidth','PetalLength','PetalWidth', 'Species']\n",
    "SPECIES = [\"Setosa\", \"Versicolor\", \"Virginica\"]\n",
    "\n",
    "train_path = tf.keras.utils.get_file(\n",
    "    \"iris_training.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_training.csv\")\n",
    "test_path = tf.keras.utils.get_file(\n",
    "    \"iris_test.csv\", \"https://storage.googleapis.com/download.tensorflow.org/data/iris_test.csv\")\n",
    "\n",
    "train = pd.read_csv(train_path, names=COLUMN_NAMES, header=0)\n",
    "test = pd.read_csv(test_path, names=COLUMN_NAMES, header=0)\n",
    "\n",
    "y_train = train.pop('Species')\n",
    "y_test = test.pop('Species')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preparing data for our model as before, just the function is different. We just convert to a dataset and shuffle."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def input_fn(features, labels, training=True, batch_size=256):\n",
    "    # Convert the inputs to a Dataset.\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((dict(features), labels))\n",
    "\n",
    "    # Shuffle and repeat if you are in training mode.\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(1000).repeat()\n",
    "\n",
    "    return dataset.batch(batch_size)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature columns as before."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_columns = []\n",
    "\n",
    "for feature_name in train.keys():\n",
    "    feature_columns.append(tf.feature_column.numeric_column(feature_name))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's build the model. We will use a deep neural network classifier because the linear classifier may not find a linear correspondence in our data and basically fail."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier = tf.estimator.DNNClassifier(\n",
    "    feature_columns=feature_columns,\n",
    "    hidden_units=[30,10],\n",
    "    n_classes=3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training. lambda helps us avoid the double function we had in LinearRegressionML by doing the same thing but in 1 line.\n",
    "\n",
    "Steps are not really epochs. We will loop through the data set until we have trained on 5000 data points."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "classifier.train(\n",
    "    input_fn=lambda: input_fn(train, y_train), steps=5000\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Time to evaluate our model."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "result = classifier.evaluate(input_fn=lambda: input_fn(test, y_test, training=False))\n",
    "\n",
    "print('\\nTest set accuracy: {accuracy:0.3f}\\n'.format(**result))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Little script for predicting 1 flower from user input. Kinda self-explanatory."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def input_fn(features, batch_size=256):\n",
    "    # Convert the inputs to a Dataset without labels.\n",
    "    return tf.data.Dataset.from_tensor_slices(dict(features)).batch(batch_size)\n",
    "\n",
    "features = ['SepalLength', 'SepalWidth', 'PetalLength', 'PetalWidth']\n",
    "predict = {}\n",
    "\n",
    "print(\"Please type numeric values as prompted.\")\n",
    "for feature in features:\n",
    "    valid = True\n",
    "    while valid:\n",
    "        val = input(feature + \": \")\n",
    "        if not val.isdigit(): valid = False\n",
    "\n",
    "    predict[feature] = [float(val)]\n",
    "\n",
    "predictions = classifier.predict(input_fn=lambda: input_fn(predict))\n",
    "for pred_dict in predictions:\n",
    "    class_id = pred_dict['class_ids'][0]\n",
    "    probability = pred_dict['probabilities'][class_id]\n",
    "\n",
    "    print('Prediction is \"{}\" ({:.1f}%)'.format(\n",
    "        SPECIES[class_id], 100 * probability))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "That's it for classification. Really useful ML in my opinion."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
